# Semantic Search + LLM Project

## ğŸ“Œ Project Overview
This project is designed to process uploaded PDF documents and perform **semantic search** using **Large Language Models (LLM)** to generate optimal answers. Instead of simple keyword matching, it employs **semantic similarity-based document retrieval** combined with **LLM-generated structured responses**.

## ğŸ¯ Project Objectives
- Enable users to quickly find relevant information through **semantic search**.
- Provide **LLM-powered summarization** of retrieved documents for coherent and logical answers.
- Develop a **browser-accessible web interface** for seamless user interaction.
- Utilize **Docker for containerized deployment** to ensure easy setup and execution.

## âš¡ Key Features
### âœ… PDF Upload & Preprocessing
- Users can upload PDF documents, which are then **processed for text extraction**.
- Extracted text is **embedded into vector representations** and stored in **FAISS/ChromaDB**.

### âœ… Semantic Search (Vector-based Retrieval)
- Converts user queries into vector embeddings to **find the most semantically similar document snippets**.
- Scores and ranks retrieved results based on relevance.

### âœ… LLM-based Answer Generation
- Retrieves relevant document snippets and **passes them to LLM for summarization**.
- Ensures **coherent and structured responses** beyond simple keyword matching.

### âœ… Browser-based UI
- Provides a **user-friendly interface** for query input, search results, and document management.
- Built with **Streamlit or React**.

## ğŸ”§ Tech Stack
| Component | Technology |
|------------|-------------|
| **Backend API** | FastAPI (Python) |
| **Frontend** | Streamlit or React |
| **Vector Store** | FAISS or ChromaDB |
| **Embedding Model** | Sentence Transformers (`all-mpnet-base-v2`) |
| **LLM Engine** | GPT-4, Claude, Llama3 |
| **Containerization** | Docker, Docker Compose |
| **Build & Deployment** | Makefile |
| **PDF Processing** | PyMuPDF, pdfminer.six |

## ğŸ“Š Data Flow
```
1ï¸âƒ£ User inputs a query via the web interface
      â†“
2ï¸âƒ£ Query is embedded using Sentence Transformers
      â†“
3ï¸âƒ£ FAISS or ChromaDB searches for semantically similar document snippets
      â†“
4ï¸âƒ£ Retrieved documents are scored and ranked for relevance
      â†“
5ï¸âƒ£ LLM constructs a response using the retrieved context
      â†“
6ï¸âƒ£ LLM generates a structured summary and answer
      â†“
7ï¸âƒ£ The response is displayed in the web interface
```

## ğŸš€ Development & Execution
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/coisu/semantic-search-llm.git
cd semantic-search-llm
```

### 2ï¸âƒ£ Run the Docker Containers
```bash
make build
make run
```

### 3ï¸âƒ£ Access the Web Interface
```
http://localhost:8501  (Streamlit UI)
http://localhost:8000/docs  (FastAPI Swagger UI)
```

## ğŸ“Œ Future Enhancements
- ğŸ”„ Optimize LLM inference speed and implement caching
- ğŸ” Add similar document recommendations
- ğŸ“„ Extend OCR functionality for scanned PDFs
